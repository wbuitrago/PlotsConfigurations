# nuisances

#nuisances = {}

# name of samples here must match keys in samples.py 

# imported from samples.py:
# samples, treeBaseDir, mcProduction, mcSteps
# imported from cuts.py
# cuts

from LatinoAnalysis.Tools.commonTools import getSampleFiles, getBaseW, addSampleWeight

def nanoGetSampleFiles(inputDir, Sample):
    return getSampleFiles(inputDir, Sample, False, 'nanoLatino_')

try:
    mc_emb = [skey for skey in samples if skey != 'DATA' and skey != 'Dyveto' and not skey.startswith('Fake')]
    mc = [skey for skey in mc_emb if skey != 'Dyemb']
except NameError:
    mc = []
    cuts = {}
    nuisances = {}
    def makeMCDirectory(x=''):
        return ''

from LatinoAnalysis.Tools.HiggsXSection import HiggsXSection
HiggsXS = HiggsXSection()


cuts0j = []
cuts1j = []
cuts2j = []

for k in cuts:
  for cat in cuts[k]['categories']:
    if '0j' in cat: cuts0j.append(k+'_'+cat)
    elif '1j' in cat: cuts1j.append(k+'_'+cat)
    elif '2j' in cat: cuts2j.append(k+'_'+cat)
    else: print 'WARNING: name of category does not contain either 0j,1j,2j'

################################ EXPERIMENTAL UNCERTAINTIES  #################################

#### Luminosity

#nuisances['lumi'] = {
#    'name': 'lumi_13TeV_2018',
#    'type': 'lnN',
#    'samples': dict((skey, '1.025') for skey in mc if skey not in ['WW', 'top', 'DY'])
#}

nuisances['lumi_Uncorrelated'] = {
        'name': 'lumi_13TeV_2018',
        'type': 'lnN',
        'samples': dict((skey, '1.015') for skey in mc if skey not in ['WW', 'top', 'DY'])
}

nuisances['lumi_correlated'] = {
        'name': 'lumi_13TeV_correlated',
        'type': 'lnN',
        'samples': dict((skey, '1.02') for skey in mc if skey not in ['WW', 'top', 'DY'])
}

nuisances['lumi_correlated_1718'] = {
        'name': 'lumi_13TeV_correlated_1718',
        'type': 'lnN',
        'samples': dict((skey, '1.002') for skey in mc if skey not in ['WW', 'top', 'DY'])
}  

# #### FAKES

# nuisances['fake_syst_e'] = {
#     'name': 'CMS_fake_syst_e',
#     'type': 'lnN',
#     'samples': {
#         'Fake_e': '1.3'
#     },
#     #'cutspost': lambda self, cuts: [cut for cut in cuts if 'mm' not in cut],
# }

# nuisances['fake_syst_m'] = {
#     'name': 'CMS_fake_syst_m',
#     'type': 'lnN',
#     'samples': {
#         'Fake_m': '1.3'
#     },
#     #'cutspost': lambda self, cuts: [cut for cut in cuts if 'ee' not in cut],
# }

# nuisances['fake_ele'] = {
#     'name': 'CMS_fake_e_2018',
#     'kind': 'weight',
#     'type': 'shape',
#     'samples': {
#         'Fake': ['fakeWEleUp', 'fakeWEleDown'],
#     }
# }

# nuisances['fake_ele_stat'] = {
#     'name': 'CMS_fake_stat_e_2018',
#     'kind': 'weight',
#     'type': 'shape',
#     'samples': {
#         'Fake': ['fakeWStatEleUp', 'fakeWStatEleDown']
#     }
# }

# nuisances['fake_mu'] = {
#     'name': 'CMS_fake_m_2018',
#     'kind': 'weight',
#     'type': 'shape',
#     'samples': {
#         'Fake': ['fakeWMuUp', 'fakeWMuDown'],
#     }
# }

# nuisances['fake_mu_stat'] = {
#     'name': 'CMS_fake_stat_m_2018',
#     'kind': 'weight',
#     'type': 'shape',
#     'samples': {
#         'Fake': ['fakeWStatMuUp', 'fakeWStatMuDown'],
#     }
# }

# ##### B-tagger

# for shift in ['jes', 'lf', 'hf', 'hfstats1', 'hfstats2', 'lfstats1', 'lfstats2', 'cferr1', 'cferr2']:
#     btag_syst = ['(btagSF%sup)/(btagSF)' % shift, '(btagSF%sdown)/(btagSF)' % shift]

#     name = 'CMS_btag_%s' % shift
#     if 'stats' in shift:
#         name += '_2018'

#     nuisances['btag_shape_%s' % shift] = {
#         'name': name,
#         'kind': 'weight',
#         'type': 'shape',
#         'samples': dict((skey, btag_syst) for skey in mc),
#     }

# ##### Trigger Efficiency

# trig_syst = ['((TriggerEffWeight_2l_u)/(TriggerEffWeight_2l))*(TriggerEffWeight_2l>0.02) + (TriggerEffWeight_2l<=0.02)', '(TriggerEffWeight_2l_d)/(TriggerEffWeight_2l)']

# nuisances['trigg'] = {
#     'name': 'CMS_eff_hwwtrigger_2018',
#     'kind': 'weight',
#     'type': 'shape',
#     'samples': dict((skey, trig_syst) for skey in mc_emb)
# }

# ##### Electron Efficiency and energy scale

# nuisances['eff_e'] = {
#     'name': 'CMS_eff_e_2018',
#     'kind': 'weight',
#     'type': 'shape',
#     'samples': dict((skey, ['SFweightEleUp', 'SFweightEleDown']) for skey in mc_emb)
# }

# nuisances['electronpt'] = {
#     'name': 'CMS_scale_e_2018',
#     'kind': 'suffix',
#     'type': 'shape',
#     'mapUp': 'ElepTup',
#     'mapDown': 'ElepTdo',
#     'samples': dict((skey, ['1', '1']) for skey in mc),
#     'folderUp': makeMCDirectory('ElepTup_suffix'),
#     'folderDown': makeMCDirectory('ElepTdo_suffix'),
#     'AsLnN': '1'
# }

# ##### Muon Efficiency and energy scale

# nuisances['eff_m'] = {
#     'name': 'CMS_eff_m_2018',
#     'kind': 'weight',
#     'type': 'shape',
#     # 'samples': dict((skey, ['ttHMVA_2l_mu_SF_Up', 'ttHMVA_2l_mu_SF_Down']) for skey in mc_emb)
#     'samples': dict((skey, ['SFweightMuUp', 'SFweightMuDown']) for skey in mc_emb)
# }

# nuisances['muonpt'] = {
#     'name': 'CMS_scale_m_2018',
#     'kind': 'suffix',
#     'type': 'shape',
#     'mapUp': 'MupTup',
#     'mapDown': 'MupTdo',
#     'samples': dict((skey, ['1', '1']) for skey in mc),
#     'folderUp': makeMCDirectory('MupTup_suffix'),
#     'folderDown': makeMCDirectory('MupTdo_suffix'),
#     'AsLnN': '1'
# }

# ##### Jet energy scale
# jes_systs = ['JESAbsolute','JESAbsolute_2018','JESBBEC1','JESBBEC1_2018','JESEC2','JESEC2_2018','JESFlavorQCD','JESHF','JESHF_2018','JESRelativeBal','JESRelativeSample_2018']

# for js in jes_systs:
#   if 'Absolute' in js: 
#     folderup = makeMCDirectory('JESAbsoluteup_suffix')
#     folderdo = makeMCDirectory('JESAbsolutedo_suffix')
#   elif 'BBEC1' in js:
#     folderup = makeMCDirectory('JESBBEC1up_suffix')
#     folderdo = makeMCDirectory('JESBBEC1do_suffix')
#   elif 'EC2' in js:
#     folderup = makeMCDirectory('JESEC2up_suffix')
#     folderdo = makeMCDirectory('JESEC2do_suffix')
#   elif 'HF' in js:
#     folderup = makeMCDirectory('JESHFup_suffix')
#     folderdo = makeMCDirectory('JESHFdo_suffix')
#   elif 'Relative' in js:
#     folderup = makeMCDirectory('JESRelativeup_suffix')
#     folderdo = makeMCDirectory('JESRelativedo_suffix')
#   elif 'FlavorQCD' in js:
#     folderup = makeMCDirectory('JESFlavorQCDup_suffix')
#     folderdo = makeMCDirectory('JESFlavorQCDdo_suffix')

#   nuisances[js] = {
#       'name': 'CMS_scale_'+js,
#       'kind': 'suffix',
#       'type': 'shape',
#       'mapUp': js+'up',
#       'mapDown': js+'do',
#       'samples': dict((skey, ['1', '1']) for skey in mc if skey not in ['VZ', 'Vg', 'VgS']),
#       'folderUp': folderup,
#       'folderDown': folderdo,
#       'AsLnN': '1'
#   }

# ##### Jet energy resolution

# nuisances['JER'] = {
#     'name': 'CMS_res_j_2018',
#     'kind': 'suffix',
#     'type': 'shape',
#     'mapUp': 'JERup',
#     'mapDown': 'JERdo',
#     'samples': dict((skey, ['1', '1']) for skey in mc if skey not in ['VZ', 'Vg', 'VgS']),
#     'folderUp': makeMCDirectory('JERup_suffix'),
#     'folderDown': makeMCDirectory('JERdo_suffix'),
#     'AsLnN': '1'
# }

# ##### MET energy scale

# nuisances['met'] = {
#     'name': 'CMS_scale_met_2018',
#     'kind': 'suffix',
#     'type': 'shape',
#     'mapUp': 'METup',
#     'mapDown': 'METdo',
#     'samples': dict((skey, ['1', '1']) for skey in mc),
#     'folderUp': makeMCDirectory('METup_suffix'),
#     'folderDown': makeMCDirectory('METdo_suffix'),
#     'AsLnN': '1'
# }

# ##### Pileup

# nuisances['PU'] = {
#     'name': 'CMS_PU_2018',
#     'kind': 'weight',
#     'type': 'shape',
#     'samples': {
#         'DY': ['0.993259983266*(puWeightUp/puWeight)', '0.997656381501*(puWeightDown/puWeight)'],
#         'top': ['1.00331969187*(puWeightUp/puWeight)', '0.999199609528*(puWeightDown/puWeight)'],
#         'WW': ['1.0033022059*(puWeightUp/puWeight)', '0.997085330608*(puWeightDown/puWeight)'],
#         'ggH_hww': ['1.0036768006*(puWeightUp/puWeight)', '0.995996570285*(puWeightDown/puWeight)'],
#         'qqH_hww': ['1.00374694528*(puWeightUp/puWeight)', '0.995878596852*(puWeightDown/puWeight)'],
#     },
#     'AsLnN': '1',
# }

# ### PU ID SF uncertainty

# puid_syst = ['Jet_PUIDSF_up/Jet_PUIDSF', 'Jet_PUIDSF_down/Jet_PUIDSF']

# nuisances['jetPUID'] = {
#     'name': 'CMS_PUID_2018',
#     'kind': 'weight',
#     'type': 'shape',
#     'samples': dict((skey, puid_syst) for skey in mc)
# }

# ##### PS
# nuisances['PS_ISR']  = {
#     'name': 'PS_ISR',
#     'kind': 'weight',
#     'type': 'shape',
#     'samples': dict((skey, ['PSWeight[2]', 'PSWeight[0]']) for skey in mc if skey not in ['Vg','VgS','WWewk']), #PSWeights are buggy for some samples, we add them back by hand below
# }

# nuisances['PS_FSR']  = {
#     'name': 'PS_FSR',
#     'kind': 'weight',
#     'type': 'shape',
#     'samples': dict((skey, ['PSWeight[3]', 'PSWeight[1]']) for skey in mc if skey not in ['Vg','VgS','WWewk']), #PSWeights are buggy for some samples, we add them back by hand below
# }

# ## PS nuisances computed by hand as a function of nCleanGenJets using alternative samples (when available). Needed if nominal samples have buggy PSWeights
# nuisances['PS_ISR_ForBuggySamples']  = {
#     'name': 'PS_ISR',
#     'kind': 'weight',
#     'type': 'shape',
#     'samples': {
#         'Vg'     : ['1.00227428567253*(nCleanGenJet==0) + 1.00572014989997*(nCleanGenJet==1) + 0.970824885256465*(nCleanGenJet==2) + 0.927346068071086*(nCleanGenJet>=3)', '0.996488506572636*(nCleanGenJet==0) + 0.993582795375765*(nCleanGenJet==1) + 1.03643678934568*(nCleanGenJet==2) + 1.09735277266955*(nCleanGenJet>=3)'],
#         'VgS'    : ['1.0000536116408023*(nCleanGenJet==0) + 1.0100100693580492*(nCleanGenJet==1) + 0.959068359375*(nCleanGenJet==2) + 0.9117049260469496*(nCleanGenJet>=3)', '0.9999367833485968*(nCleanGenJet==0) + 0.9873682892005163*(nCleanGenJet==1) + 1.0492717737268518*(nCleanGenJet==2) + 1.1176958835210322*(nCleanGenJet>=3)'],
#         'WWewk'    : ['1./1.00259*(nCleanGenJet==0) + 1./1.0179*(nCleanGenJet==1) + 1./1.01821*(nCleanGenJet==2) + 1./0.965982*(nCleanGenJet>=3)', '1./0.998322*(nCleanGenJet==0) + 1./0.979654*(nCleanGenJet==1) + 1./0.978425*(nCleanGenJet==2) + 1./1.04488*(nCleanGenJet>=3)'],
#     },
# }

# nuisances['PS_FSR_ForBuggySamples']  = {
#     'name': 'PS_FSR',
#     'kind': 'weight',
#     'type': 'shape',
#     'samples': {
#         'Vg'     : ['0.999935529935028*(nCleanGenJet==0) + 0.997948255568351*(nCleanGenJet==1) + 1.00561645493085*(nCleanGenJet==2) + 1.0212896960035*(nCleanGenJet>=3)', '1.00757702771109*(nCleanGenJet==0) + 1.00256681166083*(nCleanGenJet==1) + 0.93676371569867*(nCleanGenJet==2) + 0.956448336052435*(nCleanGenJet>=3)'],
#         'VgS'    : ['0.9976593177227735*(nCleanGenJet==0) + 1.0016125187585532*(nCleanGenJet==1) + 1.0049344618055556*(nCleanGenJet==2) + 1.0195631514301164*(nCleanGenJet>=3)', '1.0026951855766457*(nCleanGenJet==0) + 1.0008132148661049*(nCleanGenJet==1) + 1.003949291087963*(nCleanGenJet==2) + 0.9708160910230832*(nCleanGenJet>=3)'],
#         'WWewk'    : ['1./0.991982*(nCleanGenJet==0) + 1./0.995154*(nCleanGenJet==1) + 1./1.00456*(nCleanGenJet==2) + 1./1.00597*(nCleanGenJet>=3)', '1./1.01669*(nCleanGenJet==0) + 1./1.01253*(nCleanGenJet==1) + 1./0.997909*(nCleanGenJet==2) + 1./0.991305*(nCleanGenJet>=3)'],
#     },
# }


# # An overall 1.5% UE uncertainty will cover all the UEup/UEdo variations
# # And we don't observe any dependency of UE variations on njet
# nuisances['UE']  = {
#                 'name'  : 'UE_CP5',
#                 'skipCMS' : 1,
#                 'type': 'lnN',
#                 'samples': dict((skey, '1.015') for skey in mc), 
# }


# ####### Generic "cross section uncertainties"

# # From 2018 v6
# # apply_on = {
# #     'top': [
# #         'isSingleTop * 1.0816 + isTTbar',
# #         'isSingleTop * 0.9184 + isTTbar'
# #     ]
# # }

# apply_on = {
#     'top': [
#         '(topGenPt * antitopGenPt <= 0.) * 1.0816 + (topGenPt * antitopGenPt > 0.)',
#         '(topGenPt * antitopGenPt <= 0.) * 0.9184 + (topGenPt * antitopGenPt > 0.)'
#     ]
# }

# nuisances['singleTopToTTbar'] = {
#     'name': 'singleTopToTTbar',
#     'skipCMS': 1,
#     'kind': 'weight',
#     'type': 'shape',
#     'samples': apply_on
# }

# ## Top pT reweighting uncertainty

# # nuisances['TopPtRew'] = {
# #     'name': 'CMS_topPtRew',   # Theory uncertainty
# #     'kind': 'weight',
# #     'type': 'shape',
# #     'samples': {'top': ["Top_pTrw*Top_pTrw", "1."]},
# #     'symmetrize': True
# # }

# nuisances['VgStar'] = {
#     'name': 'CMS_hww_VgStarScale',
#     'type': 'lnN',
#     'samples': {
#         'VgS_L': '1.25'
#     }
# }

# nuisances['VZ'] = {
#     'name': 'CMS_hww_VZScale',
#     'type': 'lnN',
#     'samples': {
#         'VgS_H': '1.16'
#     }
# }

# ##### Renormalization & factorization scales

# ## Shape nuisance due to QCD scale variations
# # LHE scale variation weights (w_var / w_nominal)

# ## This should work for samples with either 8 or 9 LHE scale weights (Length$(LHEScaleWeight) == 8 or 9)
# variations = ['LHEScaleWeight[0]', 'LHEScaleWeight[1]', 'LHEScaleWeight[3]', 'LHEScaleWeight[Length$(LHEScaleWeight)-4]', 'LHEScaleWeight[Length$(LHEScaleWeight)-2]', 'LHEScaleWeight[Length$(LHEScaleWeight)-1]']
# VBSvariations = ['LHEScaleWeight[0]/1.0594', 'LHEScaleWeight[2]/0.9453'] # LO samples include only variations on muF scale


# topvars0j = []
# topvars1j = []
# topvars2j = []
# WWvars2j  = []

# # FIXME these need to be recalculated for 2018
# ## Factors computed to renormalize the top scale variations such that the integral is not changed in each RECO jet bin (we have rateParams for that)
# topScaleNormFactors0j = {'LHEScaleWeight[3]': 1.0026322046882807, 'LHEScaleWeight[0]': 1.0761381504953040, 'LHEScaleWeight[1]': 1.0758902481739956, 'LHEScaleWeight[Length$(LHEScaleWeight)-1]': 0.9225780960271310, 'LHEScaleWeight[Length$(LHEScaleWeight)-4]': 1.0006689791003040, 'LHEScaleWeight[Length$(LHEScaleWeight)-2]': 0.9242759920995479}
# topScaleNormFactors1j = {'LHEScaleWeight[3]': 1.0088973745933350, 'LHEScaleWeight[0]': 1.0858717477880675, 'LHEScaleWeight[1]': 1.0809970696561464, 'LHEScaleWeight[Length$(LHEScaleWeight)-1]': 0.9115155831354494, 'LHEScaleWeight[Length$(LHEScaleWeight)-4]': 0.9950909615738225, 'LHEScaleWeight[Length$(LHEScaleWeight)-2]': 0.9194241285459210}
# topScaleNormFactors2j = {'LHEScaleWeight[3]': 1.0236911155246506, 'LHEScaleWeight[0]': 1.1249360990045656, 'LHEScaleWeight[1]': 1.1054771659922622, 'LHEScaleWeight[Length$(LHEScaleWeight)-1]': 0.8819750427294990, 'LHEScaleWeight[Length$(LHEScaleWeight)-4]': 0.9819208264038879, 'LHEScaleWeight[Length$(LHEScaleWeight)-2]': 0.9025818187649589}


# ### WWJTo2L2Nu_NNLOPS ###
# WWScaleNormFactors2j = {
#     'LHEScaleWeight[0]': 1.05713,
#     'LHEScaleWeight[1]': 1.07387,
#     'LHEScaleWeight[3]': 0.956389,
#     'LHEScaleWeight[Length$(LHEScaleWeight)-4]': 1.03404,
#     'LHEScaleWeight[Length$(LHEScaleWeight)-2]': 0.962715,
#     'LHEScaleWeight[Length$(LHEScaleWeight)-1]': 1.00304
# }


# for var in variations:
#   topvars0j.append(var+'/'+str(topScaleNormFactors0j[var]))
#   topvars1j.append(var+'/'+str(topScaleNormFactors1j[var]))
#   topvars2j.append(var+'/'+str(topScaleNormFactors2j[var]))
#   WWvars2j.append(var+'/'+str(WWScaleNormFactors2j[var]))

# ## QCD scale nuisances for top are decorrelated for each RECO jet bin: the QCD scale is different for different jet multiplicities so it doesn't make sense to correlate them

# nuisances['QCDscale_WWewk'] = {
#     'name': 'QCDscale_WWewk',
#     'kind': 'weight_envelope',
#     'type': 'shape',
#     'samples': {
#         'WWewk': VBSvariations
#     }
# }

# nuisances['QCDscale_top_2j']  = {
#     'name'  : 'QCDscale_top_2j',
#     'skipCMS' : 1,
#     'kind'  : 'weight_envelope',
#     'type'  : 'shape',
#     #'cutspost' : lambda self, cuts: [cut for cut in cuts if '2j' in cut],
#     'samples'  : {
#        'top' : topvars2j,
#     }
# }

# nuisances['QCDscale_WW_2j']  = {
#     'name'  : 'QCDscale_WW_2j',
#     'skipCMS' : 1,
#     'kind'  : 'weight_envelope',
#     'type'  : 'shape',
#     #'cutspost' : lambda self, cuts: [cut for cut in cuts if '2j' in cut],
#     'samples'  : {
#        'WW' : WWvars2j,
#     }
# }

# nuisances['QCDscale_V'] = {
#     'name': 'QCDscale_V',
#     'skipCMS': 1,
#     'kind': 'weight_envelope',
#     'type': 'shape',
#     'samples': {'DY': variations},
#     'AsLnN': '1'
# }

# nuisances['QCDscale_VV'] = {
#     'name': 'QCDscale_VV',
#     'kind': 'weight_envelope',
#     'type': 'shape',
#     'samples': {
#         'Vg': variations,
#         'VZ': variations,
#         'VgS': variations
#     }
# }

# nuisances['QCDscale_ggVV'] = {
#     'name': 'QCDscale_ggVV',
#     'type': 'lnN',
#     'samples': {
#         'ggWW': '1.15',
#     },
# }

# # Uncertainty on SR/CR ratio
# nuisances['CRSR_accept_DY'] = {
#     'name': 'CMS_hww_CRSR_accept_DY',
#     'type': 'lnN',
#     'samples': {'DY': '1.02'},
#     'cuts': [cut for cut in cuts if 'DY' in cut],
#     'cutspost': (lambda self, cuts: [cut for cut in cuts if 'DY' in cut]),
# }

# # Uncertainty on SR/CR ratio
# nuisances['CRSR_accept_top'] = {
#     'name': 'CMS_hww_CRSR_accept_top',
#     'type': 'lnN',
#     'samples': {'top': '1.01'},
#     'cuts': [cut for cut in cuts if 'top' in cut],
#     'cutspost': (lambda self, cuts: [cut for cut in cuts if 'top' in cut]),
# }

# ## Use the following if you want to apply the automatic combine MC stat nuisances.
# nuisances['stat'] = {
#     'type': 'auto',
#     'maxPoiss': '10',
#     'includeSignal': '0',
#     #  nuisance ['maxPoiss'] =  Number of threshold events for Poisson modelling
#     #  nuisance ['includeSignal'] =  Include MC stat nuisances on signal processes (1=True, 0=False)
#     'samples': {}
# }

# ##rate parameters
# nuisances['DYnorm2j_hardJets']  = {
#                  'name'  : 'CMS_hww_DYnorm2j_hardJets',
#                  'samples'  : {
#                    'DY_hardJets' : '1.00',
#                      },
#                  'type'  : 'rateParam',
#                  'cuts'  : cuts2j
#                 }

# nuisances['DYnorm2j_PUJets']  = {
#                  'name'  : 'CMS_hww_DYnorm2j_PUJets_2018',
#                  'samples'  : {
#                    'DY_PUJets' : '1.00',
#                      },
#                  'type'  : 'rateParam',
#                  'cuts'  : cuts2j
#                 }

# nuisances['WWnorm2j']  = {
#                'name'  : 'CMS_hww_WWnorm2j',
#                'samples'  : {
#                    'WW' : '1.00',
#                    },
#                'type'  : 'rateParam',
#                'cuts'  : cuts2j
#               }

# nuisances['ggWWnorm2j']  = {
#                'name'  : 'CMS_hww_WWnorm2j',
#                'samples'  : {
#                    'ggWW' : '1.00',
#                    },
#                'type'  : 'rateParam',
#                'cuts'  : cuts2j
#               }

# nuisances['Topnorm2j']  = {
#                'name'  : 'CMS_hww_Topnorm2j',
#                'samples'  : {
#                    'top' : '1.00',
#                    },
#                'type'  : 'rateParam',
#                'cuts'  : cuts2j
#               }


for n in nuisances.values():
    n['skipCMS'] = 1

print ' '.join(nuis['name'] for nname, nuis in nuisances.iteritems() if nname not in ('lumi', 'stat'))
